<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>cold's world</title><link href="http://www.linuxzen.com/" rel="alternate"></link><link href="http://www.linuxzen.com/feeds/fu-zai-jun-heng.atom.xml" rel="self"></link><id>http://www.linuxzen.com/</id><updated>2012-04-16T14:25:00+08:00</updated><entry><title>lvs+keepalived实现高可用群集配置详解</title><link href="http://www.linuxzen.com/lvskeepalivedshi-xian-gao-ke-yong-qun-ji-pei-zhi-xiang-jie.html" rel="alternate"></link><updated>2012-04-16T14:25:00+08:00</updated><author><name>cold</name></author><id>tag:www.linuxzen.com,2012-04-16:lvskeepalivedshi-xian-gao-ke-yong-qun-ji-pei-zhi-xiang-jie.html</id><summary type="html">&lt;p&gt;lvs是一个开源的软件，由毕业于国防科技大学的章文嵩博士于1998年5月创立(中国人的项目)，可以实现LINUX平台下的简单负载均衡。LVS是Linux Virtual Server的缩写，意思是Linux虚拟服务器。本文将介绍lvs结合keepalived实现一个高科用的Linux群集系统.&lt;/p&gt;
&lt;p&gt;lvs有三种工作模式NAT(地址转换),IP Tunneling(IP隧道)、Direct Routing(直接路由)。
工作效率最低的是NAT模式,但NAT模式可以用于各种系统,各种环境的负载均衡,只需要一个公网ip即可实现
IP Tunneling模式调度器将连接分发到不同的后端real server,然后由real server处理请求直接相应给用户,大大提高了调度器的调度效率,后端real server没有物理位置和逻辑关系的限制,后端real server可以在Lan/Wlan,但是后端real server必须支持IP隧道协议.
DR(Direct Routing)是效率最高的,与IP Tunneling类似,都是处理一般连接,将请求给后端real server,然后由real server处理请求直接相应给用户,Direct Routing与IP Tunneling相比，没有IP封装的开销，但由于采用物理层,所以DR模式的调度器和后端real server必须在一个物理网段里,中间不能过路由器(也就是一个交换机相连).&lt;/p&gt;
&lt;p&gt;lvs支持8种不同的调度算法轮叫(rr)、加权轮叫(wrr)、最小连接(lc)、加权最小连接(wlc)、基于局部性最小连接(lblc)、带复制的基于局部性最少链接(lblcr)、目标地址散列(dh)和源地址散列(sh).&lt;/p&gt;
&lt;p&gt;下面就介绍如何来安装和配置lvs+keepalived&lt;/p&gt;
&lt;p&gt;本文使用环境:
操作系统:CentOS 5.5  32bit&lt;/p&gt;
&lt;p&gt;主调度器:192.168.3.101/24&lt;/p&gt;
&lt;p&gt;备调度器:192.168.3.102/24&lt;/p&gt;
&lt;p&gt;后端real server: 192.168.3.3/24 |192.168.3.102/24(我们这里使用备用lvs作为一个测试&lt;/p&gt;
&lt;p&gt;vip(virtual ip):192.168.3.100/24&lt;/p&gt;
&lt;p&gt;lvs在2.6的内核中是默认支持的,所以我们就不需要在来安装,但是我们需要安装用户配置工具ipvsadm&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yum -y install ipvsadm           # 分别在主从lvs上执行安装ipvsadm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们查看lvs是否支持:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lsmod ¦ grep ip_vs          #
ip_vs                  78081  1
modprobe -l¦ grep ip_vs
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_dh.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_ftp.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_lblc.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_lblcr.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_lc.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_nq.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_rr.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_sed.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_sh.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_wlc.ko
/lib/modules/2.6.18-194.el5/kernel/net/ipv4/ipvs/ip_vs_wrr.ko
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;本文介绍lvs的&lt;code&gt;DR&lt;/code&gt;模式,首先部署keepalived.本博前面已经介绍如何来安装keepalived.这里就不在只简单的贴一下步骤:&lt;/p&gt;
&lt;p&gt;在主备服务器上部署keepalived(因为前面已经rpm包安装了ipvsadm,所以就不需要重复安装):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;vi /etc/sysctl.conf
net.ipv4.ip_forward = 1 # 此参数改为1
sysctl -p # 使修改生效
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装依赖:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;yum  -y install openssl-devel
# 下载并安装keepalived
wget http://www.keepalived.org/software/keepalived-1.1.19.tar.gz
tar -zxvf keepalived-1.1.19.tar.gz
cd keepalived-1.1.19
./configure --prefix=/ \            # 安装在默认位置(配置文件,二进制文件,启动脚本放到默认位置)
--mandir=/usr/local/share/man/ \
--with-kernel-dir=/usr/src/kernels/2.6.18-194.el5-i686/    # 需要内核的头文件
make &amp;amp;&amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在主备lvs上安装keepalived完毕后我们先来配置主lvs上的keepalived:
编辑配置文件&lt;code&gt;/etc/keepalived/keepalived.conf&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! Configuration File for keepalived

global_defs {
   notification_email {
    coldnight@linuxzen.com                                   # 发生故障时发送的邮箱
   }
   notification_email_from linuxzen@linuxzen.com             # 使用哪个邮箱发送
   smtp_server linuxzen.com                                  # 发件服务器
   smtp_connect_timeout 30
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state MASTER             # 标示为主lvs
    interface eth0           # HA检测端口
    virtual_router_id 51     # 主备的virtual_router_id 必须相同
    priority 100             # 优先级,备lvs要比主lvs稍小
    advert_int 1             # VRRP Multicast 广播周期秒数
    authentication {         # 定义认证
        auth_type PASS       # 认证方式为口令认证
        auth_pass 1111       # 定义口令
    }
    virtual_ipaddress {      # 定义vip
        192.168.3.100        # 多个vip可换行添加
    }
}

virtual_server 192.168.3.100 80 {
    delay_loop 6       # 每隔6秒查看realserver状态
    lb_algo wlc        # 调度算法为加权最小连接数
    lb_kind DR         # lvs工作模式为DR(直接路由)模式
    nat_mask 255.255.255.0
    persistence_timeout 50  # 同一IP 的连接50秒内被分配到同一台realserver(测试时建议改为0)
    protocol TCP            # 用TCP监测realserver的状态

    real_server 192.168.3.3 80 {       # 定义realserver
        weight 3                       # 定义权重
        TCP_CHECK {  # 注意TCP_CHECK和{之间的空格,如果没有的话只会添加第一个realserver
            connect_timeout 3          # 三秒无响应超时
            nb_get_retry 3
            delay_before_retry 3
            connect_port 80
        }
    }
    real_server 192.168.3.102 80 {
        weight 3
        TCP_CHECK {
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
            connect_port 80
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置备用lvs的keepalived,只需要将state MASTER 改为state BACKUP,降低priority 100 的值:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;! Configuration File for keepalived

global_defs {
   notification_email {
    coldnight@linuxzen.com                               # 发生故障时发送的邮箱
   }
   notification_email_from linuxzen@linuxzen.com         # 使用哪个邮箱发送
   smtp_server linuxzen.com                              # 发件服务器
   smtp_connect_timeout 30
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state BACKUP              # 标示为备lvs
    interface eth0            # HA检测端口
    virtual_router_id 51      # 主备的virtual_router_id 必须相同
    priority 99               # 优先级,备lvs要比主lvs稍小
    advert_int 1              # VRRP Multicast 广播周期秒数
    authentication {          # 定义认证
        auth_type PASS        # 认证方式为口令认证
        auth_pass 1111        # 定义口令
    }
    virtual_ipaddress {       # 定义vip
        192.168.3.100         # 多个vip可换行添加
    }
}

virtual_server 192.168.3.100 80 {
    delay_loop 6      # 每隔6秒查看realserver状态
    lb_algo wlc       # 调度算法为加权最小连接数
    lb_kind DR        # lvs工作模式为DR(直接路由)模式
    nat_mask 255.255.255.0
    persistence_timeout 50  # 同一IP 的连接50秒内被分配到同一台realserver
    protocol TCP            # 用TCP监测realserver的状态

    real_server 192.168.3.3 80 {       # 定义realserver
        weight 3                       # 定义权重
        TCP_CHECK {    # 注意TCP_CHECK和{之间的空格,如果没有的话只会添加第一个realserver
            connect_timeout 3          # 三秒无响应超时
            nb_get_retry 3
            delay_before_retry 3
            connect_port 80
        }
    }
    real_server 192.168.3.102 80 {
        weight 3
        TCP_CHECK {
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
            connect_port 80
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由于使用keepalived就不需要使用脚本来配置lvs调度器,但是这里我们还是会给出一个脚本内容,但我们不会用到这个脚本:lvs已经内置于内核,配置命令是ipvsadm,所以lvs的一些操作是通过ipvsadm来控制.下面我们就编写脚本来实现lvs的DR模式:&lt;/p&gt;
&lt;p&gt;编写脚本lvsdr:&lt;/p&gt;
&lt;p&gt;我们把lvs&lt;code&gt;vi /etc/init.d/lvsdr&lt;/code&gt;添加如下内容&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;#!/bin/sh
# 定义虚拟ip
VIP=192.168.3.100
# 定义realserver,并已逗号分开
RIPS=192.168.3.3,192.168.3.102 #,192.168.3.5,192.168.3.6

# 定义提供服务的端口
SERVICE=80

# 调用init.d脚本的标准库
. /etc/rc.d/init.d/functions
case $1 in
        start)
        echo &amp;quot;Start LVS of DR Mode&amp;quot;
        # lvs dr模式不需要路由转发,但是keepalived需要
        #echo &amp;quot;0&amp;quot; &amp;gt; /proc/sys/net/ipv4/ip_forward
        # 开启icmp包重定向
        echo &amp;quot;1&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/all/send_redirects
        echo &amp;quot;1&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/default/send_redirects
        echo &amp;quot;1&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/eth0/send_redirects
        # 绑定虚拟ip
        ifconfig eth0:0 $VIP broadcast $VIP netmask 255.255.255.255 up
        route add -host $VIP dev eth0:0
        # 清除lvs规则
        ipvsadm -C
        # 添加一条虚拟服务器记录
    # -p指定一定的时间内将相同的客户端分配到同一台后端服务器
    # 用于解决session的问题,测试时或有别的解决方案时建议去掉
        ipvsadm -A -t $VIP:$SERVICE -s wlc -p

        # 添加真实服务器记录
        for RIP in `echo $RIPS ¦sed  -e 's/,/\n/g'`
        do
                ipvsadm -a -t $VIP:$SERVICE -r $RIP:$SERVICE -g -w 1
        done
        # 设置tcp tcpfin  udp的超时连接值
        ipvsadm --set 30 120 300
        ipvsadm
        ;;

        stop)
        echo &amp;quot;Stop LVS DR&amp;quot;
        ifconfig eth0:0 down
        ipvsadm -C
        ;;
        *)
        echo &amp;quot;Usage:$0 {start ¦ stop}&amp;quot;
        exit 1
esac
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编辑完毕保存退出,然后给这个脚本执行权限:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chmod +x /etc/init.d/lvsdr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后就可以通过service命令来启动lvs dr模式&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service lvsdr start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;将这个脚本分别放到主备lvs的/etc/init.d/下,赋予执行权限.
我们真正需要的是realserver的脚本,下面我们来编写realserver脚本,同样放在/etc/init.d/下,编辑rs脚本:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;vi /etc/init.d/lvsrs
#!/bin/sh
VIP=192.168.3.100
. /etc/rc.d/init.d/functions
case $1 in
        start)
        echo &amp;quot;lo:0 port starting&amp;quot;
        # 为了相应lvs调度器转发过来的包,需在本地lo接口上绑定vip
        ifconfig lo:0 $VIP broadcast $VIP netmask 255.255.255.255 up
        # 限制arp请求
        echo &amp;quot;1&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/lo/arp_ignore
        echo &amp;quot;2&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/lo/arp_announce
        echo &amp;quot;1&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/all/arp_ignore
        echo &amp;quot;2&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/all/arp_announce
        ;;
        stop)
        echo &amp;quot;lo:0 port closing&amp;quot;
        ifconfig lo:0 down
        echo &amp;quot;0&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/lo/arp_ignore
    echo &amp;quot;0&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/lo/arp_announce
    echo &amp;quot;0&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/all/arp_ignore
    echo &amp;quot;0&amp;quot; &amp;gt; /proc/sys/net/ipv4/conf/all/arp_announce
        ;;
        *)
        echo &amp;quot;Usage: $0 {start ¦ stop}&amp;quot;
        exit 1
esac
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;给脚本赋予执行权限&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;chmod +x /etc/init.d/lvsrs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;并将这个脚本放到所有的realserver的/etc/init.d/下.下面开始测试:&lt;/p&gt;
&lt;p&gt;先来确认下我们做的变动:主从lvs分别安装keepalived,并且在/etc/init.d/下添加了lvsdr脚本(不使用).&lt;/p&gt;
&lt;p&gt;后端realserver分别在/etc/init.d/下添加了lvsrs脚本.我们先测试keepalived:&lt;/p&gt;
&lt;p&gt;首先在主调度器上启动keepalived:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service keepalived start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看日志文件:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tail -50 /var/log/message
Mar 21 22:29:10 master kernel: device eth0 left promiscuous mode
Mar 21 22:29:10 master kernel: type=1700 audit(1332340150.598:12): dev=eth0 prom=0 old_prom=256 auid=4294967295 ses=4294967295
Apr 16 13:31:32 master Keepalived: Starting Keepalived v1.1.19 (04/16,2012)
Apr 16 13:31:32 master Keepalived_healthcheckers: Netlink reflector reports IP 192.168.3.101 added
Apr 16 13:31:32 master Keepalived_healthcheckers: Registering Kernel netlink reflector
Apr 16 13:31:32 master Keepalived_healthcheckers: Registering Kernel netlink command channel
Apr 16 13:31:32 master Keepalived_healthcheckers: Opening file '/etc/keepalived/keepalived.conf'.
Apr 16 13:31:32 master Keepalived_healthcheckers: Configuration is using : 8897 Bytes
Apr 16 13:31:32 master Keepalived_healthcheckers: Using LinkWatch kernel netlink reflector...
Apr 16 13:31:32 master Keepalived: Starting Healthcheck child process, pid=5369
Apr 16 13:31:32 master Keepalived: Starting VRRP child process, pid=5370
Apr 16 13:31:32 master Keepalived_vrrp: Netlink reflector reports IP 192.168.3.101 added
Apr 16 13:31:32 master Keepalived_vrrp: Registering Kernel netlink reflector
Apr 16 13:31:32 master Keepalived_vrrp: Registering Kernel netlink command channel
Apr 16 13:31:32 master Keepalived_vrrp: Registering gratutious ARP shared channel
Apr 16 13:31:32 master Keepalived_vrrp: Opening file '/etc/keepalived/keepalived.conf'.
Apr 16 13:31:32 master Keepalived_vrrp: Configuration is using : 36512 Bytes
Apr 16 13:31:32 master Keepalived_vrrp: Using LinkWatch kernel netlink reflector...
Apr 16 13:31:32 master Keepalived_vrrp: VRRP sockpool: [ifindex(2), proto(112), fd(10,11)]
Apr 16 13:31:33 master Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
Apr 16 13:31:34 master Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
Apr 16 13:31:34 master Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
Apr 16 13:31:34 master Keepalived_healthcheckers: Netlink reflector reports IP 192.168.3.100 added
Apr 16 13:31:34 master Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.3.100
Apr 16 13:31:34 master Keepalived_vrrp: Netlink reflector reports IP 192.168.3.100 added
Apr 16 13:31:39 master Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.3.100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在备用调度器上启动keepalived然后查看日志:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Apr 16 13:33:35 slave Keepalived_vrrp: VRRP_Instance(VI_1) Entering BACKUP STATE
Apr 16 13:33:35 slave Keepalived_vrrp: VRRP sockpool: [ifindex(2), proto(112), fd(11,12)]
Apr 16 13:33:35 slave Keepalived_healthcheckers: Netlink reflector reports IP 192.168.3.102 added
Apr 16 13:33:35 slave Keepalived_healthcheckers: Registering Kernel netlink reflector
Apr 16 13:33:35 slave Keepalived_healthcheckers: Registering Kernel netlink command channel
Apr 16 13:33:35 slave Keepalived_healthcheckers: Opening file '/etc/keepalived/keepalived.conf'.
Apr 16 13:33:35 slave Keepalived_healthcheckers: Configuration is using : 8895 Bytes
Apr 16 13:33:35 slave kernel: IPVS: [wlc] scheduler registered.
Apr 16 13:33:35 slave Keepalived_healthcheckers: Using LinkWatch kernel netlink reflector...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在主调度器上执行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;service keepalived stop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看备用调度器日志:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tail -20 /var/log/message
Apr 16 13:39:44 slave Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
Apr 16 13:39:45 slave Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
Apr 16 13:39:45 slave Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
Apr 16 13:39:45 slave Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.3.100
Apr 16 13:39:45 slave Keepalived_vrrp: Netlink reflector reports IP 192.168.3.100 added
Apr 16 13:39:45 slave Keepalived_healthcheckers: Netlink reflector reports IP 192.168.3.100 added
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我们看到keepalived已经成功切换.&lt;/p&gt;
&lt;p&gt;然后我们使用ipvsadm命令查看(在此之前要确认后端realserver已经启动了web服务):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ipvsadm
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.3.100:http wlc
  -&amp;gt; 192.168.3.3:http             Route   3      0          0
  -&amp;gt; 192.168.3.102:http           Route   3      0          0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后分别启动后端realserver的lvsrs服务:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;servie lvsrs start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后浏览器访问192.168.3.100,如果keepalived的persistence_timeout参数值为0,而且两个后端realserver是不同的内容,刷新就可以看到两个不同的页面交替.&lt;/p&gt;</summary><category term="高可用"></category><category term="详解"></category><category term="群集"></category><category term="lvs"></category><category term="Linux"></category><category term="keepalived"></category><category term=""></category></entry><entry><title>nginx+keepalived配置高可用HTTP群集</title><link href="http://www.linuxzen.com/nginxkeepalivedpei-zhi-gao-ke-yong-httpqun-ji.html" rel="alternate"></link><updated>2012-02-09T17:35:00+08:00</updated><author><name>cold</name></author><id>tag:www.linuxzen.com,2012-02-09:nginxkeepalivedpei-zhi-gao-ke-yong-httpqun-ji.html</id><summary type="html">&lt;p&gt;Nginx不仅是一款优秀的WEB服务器,同时可以根据nginx的反代理可以配置成强大的负载均衡器.这里就介绍如何把nginx配置成负载均衡器,并结合keepalived配置高可用的集群.
一般集群主要架构为:&lt;/p&gt;
&lt;p&gt;前端为负载均衡器两个:主/备,两种工作方式,一种是备机待机状态,主机故障时备机接管主机工作实现故障庄毅,在主机故障恢复完成时备机继续仅需待机状态,第二种是主备同时工作,一台宕机另外一台自动接管另一台的工作实现故障转移.
第一种方式可以通过将域名解析到一个虚拟ip(vip)上,主负载均衡器绑定虚拟ip,当主负载均衡器出现故障时,通过keepalived自动将vip绑定到备用负载均衡器上同时arping网关刷新MAC地址.,避免单点故障.
第二种方式主备同时绑定一个vip,把域名通过DNS轮询的方式解析到这两个服务器上,主机出现故障,备机就将主机绑定vip绑定到备机上,同时arping网关刷新MAC地址.实现故障转移.&lt;/p&gt;
&lt;p&gt;中间为WEB服务器作为real server,处理请求.
后端为数据库和分布式文件系统.数据库一般为主从两台.分布式文件系统有效解决WEB服务器之间的数据同步.有的还会将图片服务器单独分离出来放在后端.&lt;/p&gt;
&lt;p&gt;本文使用环境:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CentOS 5.5 32位&lt;/li&gt;
&lt;li&gt;nginx:nginx-1.0.11&lt;/li&gt;
&lt;li&gt;keepalived：keepalived-1.1.19.tar.gz&lt;/li&gt;
&lt;li&gt;主调度器:192.168.3.1&lt;/li&gt;
&lt;li&gt;备调度器:192.168.3.2&lt;/li&gt;
&lt;li&gt;real server:192.168.3.4/5/6&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文采用第一种方式来进行vip为:192.168.3.253&lt;/p&gt;
&lt;h2&gt;一、在主备服务器上部署nginx&lt;/h2&gt;
&lt;h3&gt;1.下载&lt;/h3&gt;
&lt;pre&gt;&lt;code class="bash"&gt;wget http://nginx.org/download/nginx-1.0.11.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;2.安装&lt;/h3&gt;
&lt;pre&gt;&lt;code class="bash"&gt; yum  -y install zlib-devel pcre-devel openssl-devel  # 安装依赖
tar -zxvf nginx-1.0.11.tar.gz
cd nginx-1.0.11
./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_flv_module --with-http_gzip_static_module
make &amp;amp;amp;&amp;amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;3.配置&lt;/p&gt;
&lt;p&gt;配置主调度器的nginx,编辑nginx.conf&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;vi /usr/local/nginx/conf/nginx.conf

http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; '
    #                  '$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; '
    #                  '&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    # 添加一组真实的服务器地址池
    # 供proxy_pass和fastcgi_pass指令中使用的代理服务器
    upstream real_server_pool {
      # 后台如果有动态应用的时候,ip_hash指令可以通过hash算法
      # 将客户端请求定位到同一台后端服务器上,解决session共享,
      # 但建议用动态应用做session共享
      # ip_hash;

      # server用于指定一个后端服务器的名称和参数
      # weight代表权,重默认为1,权重越高被分配的客户端越多
      # max_fails 指定时间内对后端请求失败的次数
      # fail_timeout 达到max_fails指定的失败次数后暂停的时间
      server  192.168.3.4:80 weight=1 max_fails=2 fail_timeout=30s;
      # down参数用来标记为离线,不参与负载均衡.在ip_hash下使用
      # 在此做演示,后面测试会去掉
      server  192.168.3.5:80 weight=1 max_fails=2 fail_timeout=30s down;
      # backup仅仅在非backup服务器宕机或繁忙的时候使用
      # (在此做演示,后面测试会去掉)
      server  192.168.3.6:80 weight=1 max_fails=2 fail_timeout=30s backup;
    }
    server {
        listen       192.168.3.1:80;
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            #root   html;
            #index  index.html index.htm;
            # 使用upstream设置的一组代理服务器
            # 如果后端服务器出现502或504等执行错误时,
            # 将自动将请求转发给负载均衡池中的另一台服务器.
            proxy_next_upstream http_502 http_504 error timeout invalid_header;
            proxy_pass http://real_server_pool;
            proxy_set_header Host $host;
            proxy_set_header X-Forwarded-For $remote_addr;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(&lt;code&gt;注意:&lt;/code&gt;配置文件中注释ip_hash,以为ip_hash这个功能将保证这个客户端请求总是被转发到一台服务器上,所以如果启用了ip_hash指令,将不能再使用weight(权重参数),配置文件中加入为解释ip_hash指令)
配置备用nginx,将监听ip改为备用调度器的ip&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;http {
    include       mime.types;
    default_type  application/octet-stream;

    #log_format  main  '$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; '
    #                  '$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; '
    #                  '&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;';

    #access_log  logs/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    #keepalive_timeout  0;
    keepalive_timeout  65;

    #gzip  on;

    upstream real_server_pool {
      #ip_hash;
      server  192.168.3.4:80 weight=1 max_fails=2 fail_timeout=30s;
      server  192.168.3.5:80 weight=1 max_fails=2 fail_timeout=30s;
      server  192.168.3.6:80 weight=1 max_fails=2 fail_timeout=30s;
    }
    server {
        listen       192.168.3.2:80;             # 监听ip改为本地ip
        server_name  localhost;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            #root   html;
            #index  index.html index.htm;
            proxy_next_upstream http_502 http_504 error timeout invalid_header;
            proxy_pass http://real_server_pool;
            proxy_set_header Host $host;
            proxy_set_header X-Forwarded-For $remote_addr;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后启动主备nginx:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;/usr/local/nginx/sbin/nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;二、在主备服务器上部署keepalived&lt;/h2&gt;
&lt;p&gt;安装
安装依赖:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;yum -y install kernel-devel              # 安装依赖
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;开启路由转发:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;vi /etc/sysctl.conf
net.ipv4.ip_forward = 1 # 此参数改为1
sysctl -p # 使修改生效
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先安装ipvs:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;ln -s /usr/src/kernels/2.6.18-194.el5-i686/ /usr/src/linux  # ipvs需要内核文件,做一个软连接
# 下载
wget http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.24.tar.gz
tar -zxvf ipvsadm-1.24.tar.gz
cd ipvsadm-1.24
make
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后安装keepalived&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;# 下载
wget http://www.keepalived.org/software/keepalived-1.1.19.tar.gz
tar -zxvf keepalived-1.1.19.tar.gz
cd keepalived-1.1.19
./configure --prefix=/ \            # 安装在默认位置(配置文件,二进制文件,启动脚本放到默认位置)
--mandir=/usr/local/share/man/ \
--with-kernel-dir=/usr/src/kernels/2.6.18-194.el5-i686/    # 需要内核的头文件
make &amp;amp;amp;&amp;amp;amp; make install
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;配置keepalived&lt;/h3&gt;
&lt;p&gt;编辑主调度器配置文件/etc/keepalived/keepalived.conf ###&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;global_defs {
   notification_email {
        cold_night@linuxzen.com             # 定义通知邮箱,有多个可以换行添加
}
   notification_email_from root@linuxzen.com# 定义发送邮件的邮箱
   smtp_server www.linuxzen.com             # 定义发件服务器
   smtp_connect_timeout 30                  # 定义连接smtp服务器超时时间
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state MASTER                   # 标示主备,备机上改为BACKUP
    interface eth0                 # HA监测的端口
    virtual_router_id 51           # 主备的virtual_router_id的值必须相同
    priority 100                   # 优先级,通常主要比备稍大
    advert_int 1                   # VRRP Multicast 广播周期秒数
    authentication {               # 定义认证
        auth_type PASS             # 认证方式
        auth_pass 1111             # 认证口令字
    }
    virtual_ipaddress {            # 定义vip
        192.168.3.253              # 多个可换行添加,一行一个
    }
}

virtual_server 192.168.3.253 80 {
    delay_loop 6             # 每隔 6 秒查询 realserver 状态
    lb_algo rr
    lb_kind NAT
    nat_mask 255.255.255.0
    persistence_timeout 50   # 同一IP 的连接50秒内被分配到同一台realserver
    protocol TCP             # 用TCP监测realserver的状态

    real_server 192.168.3.1 80 {
        weight 3                # 权重
        TCP_CHECK {
            connect_timeout 10  # 10秒无响应超时
            nb_get_retry 3
            delay_before_retry 3
            connect_port 80
        }
    }

    real_server 192.168.3.2 80 {
        weight 3
        TCP_CHECK {
            connect_timeout 3
            delay_before_retry 3
            connect_port 80
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;配置备用调度器的keepalived,只需要将state MASTER 改为state BACKUP,降低priority 100 的值:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;global_defs {
   notification_email {
        cold_night@linuxzen.com
}
   notification_email_from root@linuxzen.com
   smtp_server www.linuxzen.com
   smtp_connect_timeout 30
   router_id LVS_DEVEL
}

vrrp_instance VI_1 {
    state BACKUP                   # 备机上改为BACKUP
    interface eth0
    virtual_router_id 51           # 主备的virtual_router_id的值必须相同
    priority 99                    # 备用优先级小于主调度器
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.3.253
    }
}

virtual_server 192.168.3.253 80 {
    delay_loop 6
   lb_algo rr
    lb_kind NAT
    nat_mask 255.255.255.0
    persistence_timeout 50
    protocol TCP        

    real_server 192.168.3.1 80 {
        weight 3
        TCP_CHECK {
            connect_timeout 10
            nb_get_retry 3
            delay_before_retry 3
            connect_port 80
        }
    }

    real_server 192.168.3.2 80 {
        weight 3
        TCP_CHECK {
            connect_timeout 3
            delay_before_retry 3
            connect_port 80
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;主备上启动keepalived:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;service keepalived start
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;三、测试-----部署后端服务器&lt;/h2&gt;
&lt;p&gt;在后端服务器安装nginx,这里仅部署一台然后创建3个基于ip的虚拟主机供测试:
绑定ip:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;ifconfig eth0:1 192.168.3.4/24
ifconfig eth0:2 192.168.3.5/24
ifconfig eth0:3 192.168.3.6/24
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装nginx后编辑配置文件,在http块里添加:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;http {
    server {
        listen  192.168.3.4:80;
        server_name     192.168.3.4;

        location / {
             root html/s1;
             index index.html index.htm;
        }
    }

    server {
        listen  192.168.3.5:80;
        server_name     192.168.3.5;

        location / {
            root html/s2;
            index index.html index.htm;
        }
    }

    server {
        listen 192.168.3.6:80;
        server_name     192.168.3.5;

        location / {
            root html/s3;
            index index.html index.htm;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;创建虚拟主机根目录,并创建不通的首页文档:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;cd /usr/local/nginx/html/
mkdir s1 s2 s3
echo server1 &amp;amp;gt; s1/index.html
echo server2 &amp;amp;gt; s2/index.html
echo server3 &amp;amp;gt; s3/index.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动nginx:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;/usr/local/nginx/sbin/nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打开浏览器访问&lt;code&gt;http://192.168.3.253&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;刷新会看到显示不同的内容:server1,server2,server3(生产中的服务器应该是一样的)
[gallery link="file" order="DESC"]
现在停掉主调度器的keepalived&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;pkill keepalived
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看备调度器的日志:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;cat /var/log/messages
Feb 10 16:36:27 cfhost Keepalived_vrrp: VRRP_Instance(VI_1) Transition to MASTER STATE
Feb 10 16:36:28 cfhost Keepalived_vrrp: VRRP_Instance(VI_1) Entering MASTER STATE
Feb 10 16:36:28 cfhost Keepalived_vrrp: VRRP_Instance(VI_1) setting protocol VIPs.
Feb 10 16:36:28 cfhost Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.3.253
Feb 10 16:36:28 cfhost Keepalived_vrrp: Netlink reflector reports IP 192.168.3.253 added
Feb 10 16:36:28 cfhost Keepalived_healthcheckers: Netlink reflector reports IP 192.168.3.253 added
Feb 10 16:36:33 cfhost Keepalived_vrrp: VRRP_Instance(VI_1) Sending gratuitous ARPs on eth0 for 192.168.3.253
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;现在访问&lt;code&gt;http://192.168.3.253&lt;/code&gt;依然可以访问.
大家也看到了备机keepalived只有检测主机的keepalived停止的时候才会切换vip,而不是检测一台real server的某一服务(比如检测80端口的HTTP)切换vip,所以在nginx进程停止的时候,如果服务器没有宕机这时候就无法实现故障转移,所以我们编写一个检测nginx状态的脚本结合keepalived实现故障转移:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;#!/bin/bash
#filename:nsc.sh
ps aux ¦ grep nginx ¦ grep -v grep 2&amp;amp;gt; /dev/null 1&amp;amp;gt;&amp;amp;amp;2   # 过滤nginx进程
if [[ $? -eq 0 ]]               # 如果过滤有nginx进程会返回0则认为nginx存活
then
    sleep 5                     # 使脚本进入休眠
else
# 如果nginx没有存活尝试启动nginx,如果失败则杀死keepalived的进程
    /usr/local/nginx/sbin/nginx
    ps aux ¦ grep nginx ¦ grep -v grep 2&amp;amp;gt; /dev/null 1&amp;amp;gt;&amp;amp;amp;2
    if [[ $? -eq 0 ]]
    then
        pkill keepalived
    fi
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后后台运行此脚本:&lt;/p&gt;
&lt;pre&gt;&lt;code class="bash"&gt;nohup sh nsc.sh &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就实现了群集的高可靠和高可用.&lt;/p&gt;</summary><category term="高可用"></category><category term="负载均衡"></category><category term="群集"></category><category term="反向代理"></category><category term="双机"></category><category term="nginx"></category><category term="keepalived"></category></entry></feed>